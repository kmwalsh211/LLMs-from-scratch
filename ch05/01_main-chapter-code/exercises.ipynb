{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "My computer crashed randomly and something got messed up with Jupyter Notebook where it wouldn't connect to a server for a while, then when I got it working again, it still couldn't run any code blocks, including even just one line to import torch as shown in the error message below. Most solutions I ran before this started happening so I know they did work, but I couldn't figure out what the issue was to resolve it.",
   "id": "65ab7e7c48f78260"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5.1\n",
    "Use the print_sampled_tokens function to print the sampling frequencies of the softmax probabilities scaled with the temperatures shown in figure 5.14. How often is the word pizza sampled in each case? Can you think of a faster and more accurate way to determine how often the word pizza is sampled?"
   ],
   "id": "1129a330da8c02a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T03:09:59.510333Z",
     "start_time": "2025-04-25T03:06:38.939298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "\n",
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "\n",
    "temperatures = [1, 0.1, 5]  # Original, higher, lower temperature\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ],
   "id": "c86c4d9a32d56564",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      3\u001B[39m vocab = {\n\u001B[32m      4\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcloser\u001B[39m\u001B[33m\"\u001B[39m: \u001B[32m0\u001B[39m,\n\u001B[32m      5\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mevery\u001B[39m\u001B[33m\"\u001B[39m: \u001B[32m1\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     12\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33myou\u001B[39m\u001B[33m\"\u001B[39m: \u001B[32m8\u001B[39m,\n\u001B[32m     13\u001B[39m }\n\u001B[32m     14\u001B[39m inverse_vocab = {v: k \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m vocab.items()}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/CURRENT CLASSES/CPSC_352/LLMs-from-scratch/.venv/lib/python3.12/site-packages/torch/__init__.py:2222\u001B[39m\n\u001B[32m   2218\u001B[39m sys.modules.setdefault(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.classes\u001B[39m\u001B[33m\"\u001B[39m, classes)\n\u001B[32m   2220\u001B[39m \u001B[38;5;66;03m# quantization depends on torch.fx and torch.ops\u001B[39;00m\n\u001B[32m   2221\u001B[39m \u001B[38;5;66;03m# Import quantization\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2222\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m quantization \u001B[38;5;28;01mas\u001B[39;00m quantization  \u001B[38;5;66;03m# usort: skip\u001B[39;00m\n\u001B[32m   2224\u001B[39m \u001B[38;5;66;03m# Import the quasi random sampler\u001B[39;00m\n\u001B[32m   2225\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m quasirandom \u001B[38;5;28;01mas\u001B[39;00m quasirandom  \u001B[38;5;66;03m# usort: skip\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/CURRENT CLASSES/CPSC_352/LLMs-from-scratch/.venv/lib/python3.12/site-packages/torch/quantization/__init__.py:2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# mypy: allow-untyped-defs\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfake_quantize\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfuse_modules\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m fuse_modules\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfuser_method_mappings\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/CURRENT CLASSES/CPSC_352/LLMs-from-scratch/.venv/lib/python3.12/site-packages/torch/quantization/fake_quantize.py:10\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# flake8: noqa: F401\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[33;03mThis file is in the process of migration to `torch/ao/quantization`, and\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[33;03mis kept here for compatibility while the migration process is ongoing.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m      7\u001B[39m \u001B[33;03mhere.\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantization\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfake_quantize\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     11\u001B[39m     _is_fake_quant_script_module,\n\u001B[32m     12\u001B[39m     _is_per_channel,\n\u001B[32m     13\u001B[39m     _is_per_tensor,\n\u001B[32m     14\u001B[39m     _is_symmetric_quant,\n\u001B[32m     15\u001B[39m     default_fake_quant,\n\u001B[32m     16\u001B[39m     default_fixed_qparams_range_0to1_fake_quant,\n\u001B[32m     17\u001B[39m     default_fixed_qparams_range_neg1to1_fake_quant,\n\u001B[32m     18\u001B[39m     default_fused_act_fake_quant,\n\u001B[32m     19\u001B[39m     default_fused_per_channel_wt_fake_quant,\n\u001B[32m     20\u001B[39m     default_fused_wt_fake_quant,\n\u001B[32m     21\u001B[39m     default_histogram_fake_quant,\n\u001B[32m     22\u001B[39m     default_per_channel_weight_fake_quant,\n\u001B[32m     23\u001B[39m     default_weight_fake_quant,\n\u001B[32m     24\u001B[39m     disable_fake_quant,\n\u001B[32m     25\u001B[39m     disable_observer,\n\u001B[32m     26\u001B[39m     enable_fake_quant,\n\u001B[32m     27\u001B[39m     enable_observer,\n\u001B[32m     28\u001B[39m     FakeQuantize,\n\u001B[32m     29\u001B[39m     FakeQuantizeBase,\n\u001B[32m     30\u001B[39m     FixedQParamsFakeQuantize,\n\u001B[32m     31\u001B[39m     FusedMovingAvgObsFakeQuantize,\n\u001B[32m     32\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/CURRENT CLASSES/CPSC_352/LLMs-from-scratch/.venv/lib/python3.12/site-packages/torch/ao/quantization/__init__.py:28\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mqconfig_mapping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquant_type\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantization_mappings\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403 # type: ignore[no-redef]\u001B[39;00m\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantize\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m     30\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantize_jit\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/CURRENT CLASSES/CPSC_352/LLMs-from-scratch/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:18\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantized\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mreference\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnnqr\u001B[39;00m\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# Because `torch.ao.nn` uses lazy imports, we need to make\u001B[39;00m\n\u001B[32m     17\u001B[39m \u001B[38;5;66;03m# sure we import the contents explicitly here.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msparse\u001B[39;00m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfunctional\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mF\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m nn\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/CURRENT CLASSES/CPSC_352/LLMs-from-scratch/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/__init__.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m quantized\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/CURRENT CLASSES/CPSC_352/LLMs-from-scratch/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/__init__.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msparse\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantized\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dynamic\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlinear\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Linear, LinearPackedParams\n\u001B[32m      6\u001B[39m __all__ = [\n\u001B[32m      7\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdynamic\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      8\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mLinear\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      9\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mLinearPackedParams\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     10\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/CURRENT CLASSES/CPSC_352/LLMs-from-scratch/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/__init__.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlinear\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Linear\n\u001B[32m      4\u001B[39m __all__ = [\n\u001B[32m      5\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mLinear\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      6\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/CURRENT CLASSES/CPSC_352/LLMs-from-scratch/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:10\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mintrinsic\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnni\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantized\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodules\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      7\u001B[39m     _hide_packed_params_repr,\n\u001B[32m      8\u001B[39m     _quantize_weight,\n\u001B[32m      9\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msparse\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantized\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m linear\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msparse\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantized\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LinearBlockSparsePattern\n\u001B[32m     14\u001B[39m __all__ = [\u001B[33m\"\u001B[39m\u001B[33mLinear\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1354\u001B[39m, in \u001B[36m_find_and_load\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1325\u001B[39m, in \u001B[36m_find_and_load_unlocked\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:929\u001B[39m, in \u001B[36m_load_unlocked\u001B[39m\u001B[34m(spec)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:990\u001B[39m, in \u001B[36mexec_module\u001B[39m\u001B[34m(self, module)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:1086\u001B[39m, in \u001B[36mget_code\u001B[39m\u001B[34m(self, fullname)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:1186\u001B[39m, in \u001B[36mget_data\u001B[39m\u001B[34m(self, path)\u001B[39m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T23:50:29.596399Z",
     "start_time": "2025-04-24T23:50:29.535723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, probas in enumerate(scaled_probas):\n",
    "    print(\"\\n\\nTemperature =\", temperatures[i])\n",
    "    print_sampled_tokens(probas)"
   ],
   "id": "de727f31bdd36c67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Temperature = 1\n",
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "\n",
      "\n",
      "Temperature = 0.1\n",
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "985 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "15 x toward\n",
      "\n",
      "\n",
      "Temperature = 5\n",
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T23:50:49.022023Z",
     "start_time": "2025-04-24T23:50:49.005664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temp5_idx = 2\n",
    "pizza_idx = 6\n",
    "\n",
    "scaled_probas[temp5_idx][pizza_idx]\n",
    "#There is a 4.3% probabiliy \"pizza\" is sampled for temperature = 5"
   ],
   "id": "f6039ef199ed1e1e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0430)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5.2\n",
    "Play around with different temperatures and top-k settings. Based on your observa- tions, can you think of applications where lower temperature and top-k settings are desired? Likewise, can you think of applications where higher temperature and top-k settings are preferred? (It’s recommended to also revisit this exercise at the end of the chapter after loading the pretrained weights from OpenAI.)"
   ],
   "id": "1d86a0ce02fe8851"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ANSWER: Since lower top-k and temperature values lead to less random results, they are best for technical applications and uses like coding, math, and anything formulaic. On the opposite end, higher values lead to a higher degree of randomness and so they are best for creative uses like idea generation.",
   "id": "c171802f85710800"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5.3\n",
    "What are the different combinations of settings for the generate function to force deterministic behavior, that is, disabling the random sampling such that it always pro- duces the same outputs similar to the generate_simple function?"
   ],
   "id": "a842e0ffec0d4382"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ANSWER: One way to force the generate function to have deterministic behavior is setting top_k equal to None and temperature equal to 0, as this makes the model always choose the token with the highest probability, so inputting the same thing will always lead to the exact same output. Top_k doesn't matter when temperature = 0 since the token with highest probability will be chosen anyway. Another way is by setting top_k = 1, as this is functionally the same as temperature = 0 since with tip_k = 1 only the token with the highest probability will be considered at each step.",
   "id": "65bbd20da07dcc40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5.4\n",
    "After saving the weights, load the model and optimizer in a new Python session or Jupyter notebook file and continue pretraining it for one more epoch using the train_model_simple function."
   ],
   "id": "e5b0db24b811ee54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ],
   "id": "278b1bc174a20ff0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ],
   "id": "a43770a9cc1eeb3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from gpt_train import train_model_simple\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ],
   "id": "190fc5a49cf29fd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5.5\n",
    "Calculate the training and validation set losses of the GPTModel with the pretrained weights from OpenAI on the “The Verdict” dataset."
   ],
   "id": "8203894b0ac373ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ],
   "id": "8d6d807a3bb15489"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ],
   "id": "e3585b260cbd729c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ],
   "id": "954b7c37ffa94e2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from gpt_generate import load_weights_into_gpt\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ],
   "id": "c31e85b98828e24f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ],
   "id": "836c3455cf31bcf0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from gpt_train import calc_loss_loader\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "train_loss = calc_loss_loader(train_loader, gpt, device)\n",
    "val_loss = calc_loss_loader(val_loader, gpt, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "id": "5082dae91c40e372"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5.6\n",
    "Experiment with GPT-2 models of different sizes—for example, the largest 1,558 mil- lion parameter model—and compare the generated text to the 124 million model."
   ],
   "id": "97387b4d5bfa578"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ],
   "id": "4344e1870d3f2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from gpt_generate import load_weights_into_gpt\n",
    "\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-xl (1558M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=\"1558M\", models_dir=\"gpt2\")\n",
    "load_weights_into_gpt(gpt, params)"
   ],
   "id": "e71a530807e63285"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from gpt_generate import generate, text_to_token_ids, token_ids_to_text",
   "id": "86018de02caf861c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#XL Model\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "ed696cf7ae9c3ffe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
